{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3.2 - Model 7: Universal-Sentence-Encoder (latest changes on 08.02.2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For cleaning and preparing the dataset\n",
    "# -> dataframe manipulation\n",
    "# -> text manipulation\n",
    "# -> Web Scrapping\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from tabulate import tabulate\n",
    "import re\n",
    "\n",
    "import random\n",
    "\n",
    "# Module to serialize the content produced from the execution of the code\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Module to monitor the progress of a python for loop\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "# Module to manipulate text in python - NLTK package\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Module to compute word vectorizers and compute the cosine distance\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "import string\n",
    "import itertools\n",
    "\n",
    "# from IPython.core.display import display, HTML\n",
    "# display(HTML(\"<style>.container { width:70% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keras Text Classification (For creating the word embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  2.1.0\n",
      "Version:  2.1.0\n",
      "Eager mode:  True\n",
      "Hub version:  0.7.0\n",
      "GPU is NOT AVAILABLE\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from time import time\n",
    "\n",
    "#--------------------------------------------------------------\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "#---------------------------------------------------------------\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "\n",
    "import pydot\n",
    "import pydotplus\n",
    "import graphviz\n",
    "\n",
    "from IPython.display import SVG\n",
    "from tensorflow.keras.utils import model_to_dot\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import model_from_json\n",
    "import json\n",
    "\n",
    "# Import ML FLow\n",
    "import mlflow.tensorflow\n",
    "import mlflow.pyfunc\n",
    "from tensorflow.keras import regularizers\n",
    "import datetime\n",
    "\n",
    "# Import TensorBoard\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.plots as tfplots\n",
    "import tensorflow_docs.modeling as tfmodel\n",
    "from tensorflow.keras import regularizers\n",
    "# from tensorboard import default\n",
    "# from tensorboard import program\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "import bert\n",
    "from bert import tokenization\n",
    "from bert.tokenization import FullTokenizer\n",
    "\n",
    "#Visualize Model\n",
    "\n",
    "def visualize_model(model):\n",
    "    return SVG(model_to_dot(model, show_shapes= True, show_layer_names=True, dpi=65).create(prog='dot', format='svg'))\n",
    "\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "from packaging import version\n",
    "\n",
    "print(\"TensorFlow version: \", tf.__version__)\n",
    "assert version.parse(tf.__version__).release[0] >= 2, \\\n",
    "    \"This notebook requires TensorFlow 2.0 or above.\"\n",
    "\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"Hub version: \", hub.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The shape of the dataset that will be used in Keras classifier is: (49123, 13)\n"
     ]
    }
   ],
   "source": [
    "dataset_frequent_genres = pd.read_pickle('dataset_part_2_05022020.pkl')\n",
    "\n",
    "print(\"\\nThe shape of the dataset that will be used in Keras classifier is: {}\".format(dataset_frequent_genres.shape))\n",
    "\n",
    "# Split the y variable (\"genres\") to one hot encoded columns\n",
    "mlb = MultiLabelBinarizer()\n",
    "dataset_frequent_genres = dataset_frequent_genres.join(pd.DataFrame(mlb.fit_transform(dataset_frequent_genres['reduced_genres']),\n",
    "                                                                    columns=mlb.classes_,\n",
    "                                                                    index=dataset_frequent_genres.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function 1: Actors\n",
    "def unify_actors(row):\n",
    "    return ', '.join(row['actors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_frequent_genres.loc[:, 'reviews_pruned'] = dataset_frequent_genres.reviews.apply(lambda x: x[0])\n",
    "dataset_frequent_genres['actors_unified'] = dataset_frequent_genres.apply(unify_actors, axis=1)\n",
    "\n",
    "table = str.maketrans(dict.fromkeys(string.punctuation))\n",
    "dataset_frequent_genres.loc[:, 'reviews_pruned'] = dataset_frequent_genres.loc[:, 'reviews_pruned'].apply(lambda x: x.translate(table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'genres', 'rating', 'imdb_url', 'reviews_url', 'actors',\n",
       "       'plot', 'imdb_rating', 'director', 'reviews', 'sentiment_value',\n",
       "       'movie_features', 'reduced_genres', 'Action', 'Adventure', 'Animation',\n",
       "       'Children', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy',\n",
       "       'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War',\n",
       "       'Western', 'reviews_pruned', 'actors_unified'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_frequent_genres.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
    "\n",
    "class Keras_Configurations_model1():\n",
    "    \n",
    "        MAX_FEATURES = 20000\n",
    "\n",
    "class Keras_Configurations_model2():\n",
    "\n",
    "    MAX_FEATURES = 17500\n",
    "    \n",
    "class Keras_Configurations_model3():\n",
    "        \n",
    "        MAX_FEATURES = 20000\n",
    "\n",
    "# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
    "\n",
    "# Function 1\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    no_stopword_text = [word for word in text.split(' ') if not word in stop_words]\n",
    "    \n",
    "    lemmatized_text = [lemmatizer.lemmatize(word, pos='v') for word in no_stopword_text]\n",
    "    \n",
    "    lowercase_text = [word.lower() for word in lemmatized_text]\n",
    "    \n",
    "    return ' '.join(lowercase_text)\n",
    "\n",
    "def transform_actors(actors_column, dataset):\n",
    "    \n",
    "        actors_list = []\n",
    "\n",
    "        for i in range(len(actors_column)):\n",
    "            actors_list.append([element.lower() for element in actors_column.iloc[i]])\n",
    "\n",
    "        dataset.loc[:, 'clean_actors'] = actors_list\n",
    "\n",
    "    # dataset.loc[:, 'clean_actors'] = dataset.loc[:, column_name].apply(lambda x: x.lower())\n",
    "\n",
    "def transform_plot(column_name, dataset):\n",
    "    \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    dataset.loc[:, 'clean_plot_summary'] = dataset.loc[:, column_name].apply(lambda x: preprocess_text(x))\n",
    "\n",
    "def transform_features(column_name, dataset):\n",
    "    \n",
    "    dataset.loc[:, 'clean_combined_features'] = dataset.loc[:, column_name].apply(lambda x: preprocess_text(x))\n",
    "    \n",
    "def transform_reviews(column_name, dataset):\n",
    "    \n",
    "    dataset.loc[:, 'clean_reviews'] = dataset.loc[:, column_name].apply(lambda x: preprocess_text(x))\n",
    "\n",
    "# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
    "\n",
    "# Function 2\n",
    "def split_dataset(labels, dataset):\n",
    "    \n",
    "    X = dataset[['title', 'clean_actors', 'clean_plot_summary', 'clean_combined_features', 'clean_reviews', 'reduced_genres']]\n",
    "    \n",
    "    y = labels\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, shuffle= True)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "\n",
      "Transfrom the column of the actors\n",
      "\n",
      "Transfrom the column of the plot summary\n",
      "\n",
      "Transfrom the column of the movie features\n",
      "\n",
      "Transfrom the column of the movie reviews\n",
      "\n",
      "Wall time: 2min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "# Transfrom the columns\n",
    "print(\"---------------------------------------------------------------------------------\\n\")\n",
    "print(\"Transfrom the column of the actors\\n\")\n",
    "transform_actors(dataset_frequent_genres.loc[:, 'actors'], dataset_frequent_genres) # function 3: transform_actors\n",
    "\n",
    "print(\"Transfrom the column of the plot summary\\n\")\n",
    "transform_plot(\"plot\", dataset_frequent_genres) # function 3: transform_plot\n",
    "\n",
    "print(\"Transfrom the column of the movie features\\n\")\n",
    "transform_features(\"movie_features\", dataset_frequent_genres) # function 3: transform_features\n",
    "\n",
    "print(\"Transfrom the column of the movie reviews\\n\")\n",
    "transform_reviews(\"reviews_pruned\", dataset_frequent_genres) # function 3: transform_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "Split the dataset into train & validation set\n",
      "\n",
      "X_train shape:(39298, 6)\n",
      "X_test shape:(9825, 6)\n",
      "y_train shape:(39298, 17)\n",
      "y_test shape:(9825, 17)\n"
     ]
    }
   ],
   "source": [
    "# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "# Split the dataset into train & validation set\n",
    "print(\"\\n---------------------------------------------------------------------------------\")\n",
    "print(\"\\nSplit the dataset into train & validation set\\n\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_dataset(dataset_frequent_genres.iloc[:, 13:30], dataset_frequent_genres) #13:30\n",
    "\n",
    "print(\"X_train shape:{}\".format(X_train.shape))\n",
    "print(\"X_test shape:{}\".format(X_test.shape))\n",
    "print(\"y_train shape:{}\".format(y_train.shape))\n",
    "print(\"y_test shape:{}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 20.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Separate each different input column (actors, plot, features)\n",
    "\n",
    "# BECAREFUL: X_train = before balancing the data, X_train_updated_version2 is for the balanced data\n",
    "\n",
    "X_train_actors = X_train[[\"title\", \"clean_actors\", \"reduced_genres\"]]\n",
    "X_train_plot = X_train[[\"title\", \"clean_plot_summary\", \"reduced_genres\"]]\n",
    "X_train_features = X_train[[\"title\", \"clean_combined_features\", \"reduced_genres\"]]\n",
    "X_train_reviews = X_train[[\"title\", \"clean_reviews\", \"reduced_genres\"]]\n",
    "# In X_train and X_test I also use columns \"title\" and \"genres\" since they will be both used later for making inference with predictions\n",
    "\n",
    "assert X_train_actors.shape==X_train_plot.shape==X_train_features.shape==X_train_reviews.shape\n",
    "\n",
    "X_test_actors = X_test[[\"title\", \"clean_actors\", \"reduced_genres\"]]\n",
    "X_test_plot = X_test[[\"title\", \"clean_plot_summary\", \"reduced_genres\"]]\n",
    "X_test_features = X_test[[\"title\", \"clean_combined_features\", \"reduced_genres\"]]\n",
    "X_test_reviews = X_test[[\"title\", \"clean_reviews\", \"reduced_genres\"]]\n",
    "\n",
    "assert X_test_actors.shape==X_test_plot.shape==X_test_features.shape==X_test_reviews.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_features = X_train_features['clean_combined_features'].tolist() #input 1\n",
    "test_text_features = X_test_features['clean_combined_features'].tolist()\n",
    "\n",
    "train_text_plot = X_train_plot['clean_plot_summary'].tolist() #input 2\n",
    "test_text_plot = X_test_plot['clean_plot_summary'].tolist()\n",
    "\n",
    "train_text_actors = X_train_actors['clean_actors'].tolist() #input 3\n",
    "test_text_actors = X_test_actors['clean_actors'].tolist()\n",
    "\n",
    "train_text_reviews = X_train_reviews['clean_reviews'].tolist() #input 4\n",
    "test_text_reviews = X_test_reviews['clean_reviews'].tolist()\n",
    "\n",
    "train_label = y_train.values\n",
    "test_label = y_test.values\n",
    "\n",
    "train_bytes_list_features = []\n",
    "train_bytes_list_plot = []\n",
    "train_bytes_list_actors = []\n",
    "train_bytes_list_reviews = []\n",
    "\n",
    "# actor_list = []\n",
    "\n",
    "test_bytes_list_features = []\n",
    "test_bytes_list_plot = []\n",
    "test_bytes_list_actors = []\n",
    "test_bytes_list_reviews = []\n",
    "\n",
    "for i in train_text_features:\n",
    "    train_bytes_list_features.append(str.encode(i))\n",
    "for i in train_text_plot:\n",
    "    train_bytes_list_plot.append(str.encode(i))\n",
    "for i in train_text_actors:\n",
    "    train_bytes_list_actors.append(list(map(lambda x: str.encode(x), i)))\n",
    "for i in train_text_reviews:\n",
    "    train_bytes_list_reviews.append(str.encode(i))\n",
    "\n",
    "for i in test_text_features:\n",
    "    test_bytes_list_features.append(str.encode(i))\n",
    "for i in test_text_plot:\n",
    "    test_bytes_list_plot.append(str.encode(i))\n",
    "for i in test_text_actors:\n",
    "    test_bytes_list_actors.append(list(map(lambda x: str.encode(x), i)))\n",
    "for i in test_text_reviews:\n",
    "    test_bytes_list_reviews.append(str.encode(i))\n",
    "\n",
    "train_bytes_list_features = np.asarray(train_bytes_list_features)\n",
    "train_bytes_list_plot = np.asarray(train_bytes_list_plot)\n",
    "train_bytes_list_actors = np.asarray(train_bytes_list_actors)\n",
    "train_bytes_list_reviews = np.asarray(train_bytes_list_reviews)\n",
    "\n",
    "test_bytes_list_features = np.asarray(test_bytes_list_features)\n",
    "test_bytes_list_plot = np.asarray(test_bytes_list_plot)\n",
    "test_bytes_list_actors = np.asarray(test_bytes_list_actors)\n",
    "test_bytes_list_reviews = np.asarray(test_bytes_list_reviews)\n",
    "\n",
    "partial_x_train_features, x_val_features, partial_y_train, y_val = train_test_split(train_bytes_list_features, train_label, test_size=0.20, random_state=42)\n",
    "partial_x_train_plot, x_val_plot, partial_y_train, y_val = train_test_split(train_bytes_list_plot, train_label, test_size=0.20, random_state=42)\n",
    "partial_x_train_actors, x_val_actors, partial_y_train, y_val = train_test_split(train_bytes_list_actors, train_label, test_size=0.20, random_state=42)\n",
    "partial_x_train_reviews, x_val_reviews, partial_y_train, y_val = train_test_split(train_bytes_list_reviews, train_label, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'money pit, tom hanks shelley long alexander godunov maureen stapleton joe mantegna philip bosco josh mostel yakov smirnoff carmine caridi brian backer billy lombardo mia dillon john van dreelen douglass watson lucille dobrin richard benjamin young couple struggle repair hopelessly dilapidate house comedy' \n",
      "\n",
      "b'a young couple struggle repair hopelessly dilapidate house' \n",
      "\n",
      "[b'tom hanks', b'shelley long', b'alexander godunov', b'maureen stapleton', b'joe mantegna', b'philip bosco', b'josh mostel', b'yakov smirnoff', b'carmine caridi', b'brian backer', b'billy lombardo', b'mia dillon', b'john van dreelen', b'douglass watson', b'lucille dobrin'] \n",
      "\n",
      "b'i know critics rip the money pit get release they apparently didnt realize wasnt pretend masterpiece big excuse funny succeed some gag seem forecast equally funny mousehunt personally i think tom hanks need act comedies shelley long need get roles movies my favorite scene well i get giggle whenever i think whole chain reaction just kinds things anyone worry move new house although family didnt experience move houseall show richard benjamin great director actor my generation ought give recognition parent generation give also star alexander godunov one amish guy witness maureen stapleton joe mantegna josh mostel' \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(x_val_features[0],\"\\n\")\n",
    "print(x_val_plot[0], \"\\n\")\n",
    "print(x_val_actors[0], \"\\n\")\n",
    "print(x_val_reviews[0], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Token based text embedding trained on English Google News 130GB corpus. (without OOV tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python Cell no.1\n",
    "--------------------------\n",
    "\n",
    "In this below python cell I create 2 functions, which will save my model and will stop it early in case the results do not improve any further. More specifically, the <b>callback function</b> is very usefull when someone wants to test the <i>overfitting boundaries</i> of a neural network. Each time the fitting of the model achieves a better value of the monitored metric (e.g val_loss) then the model is automatically saved. On the contrary, if during the epoch fitting the model reaches a worse state than the previous epoch then the training of the model automatically stops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "# %reload_text tensorboard\n",
    "\n",
    "logdir=\".\\\\logs\\\\fit\\\\\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
    "\n",
    "# Callback function with early stopping to avodid overfit\n",
    "\n",
    "class Callback_Configurations():\n",
    "    \n",
    "    MONITOR_METRIC = 'val_loss'\n",
    "    MINIMUM_DELTA = 1\n",
    "    PATIENCE = 5\n",
    "    VERBOSE = 0\n",
    "    MODE = 'min'\n",
    "    \n",
    "def callback(saved_model, model, logdir):\n",
    "    \n",
    "    weights_fname = '{}.h5'.format(saved_model)\n",
    "\n",
    "    try:\n",
    "        with open('{}.json'.format(save_model),'r') as f:\n",
    "            model_json = json.load(f)\n",
    "        \n",
    "        model = model_from_json(model_json)\n",
    "        \n",
    "        model.load_weights('{}').format(weights_fname)\n",
    "\n",
    "    except:\n",
    "        print('\\nPre-trained weights not found. Fitting from start')\n",
    "        pass\n",
    "\n",
    "    monitor_metric = Callback_Configurations.MONITOR_METRIC\n",
    "    \n",
    "    callbacks = [\n",
    "        tfmodel.EpochDots(),\n",
    "        \n",
    "        EarlyStopping(monitor=monitor_metric,\n",
    "                      min_delta=Callback_Configurations.MINIMUM_DELTA,\n",
    "                      patience=Callback_Configurations.PATIENCE,\n",
    "                      verbose=Callback_Configurations.VERBOSE,\n",
    "                      mode=Callback_Configurations.MODE,\n",
    "                      restore_best_weights=True),\n",
    "\n",
    "        ModelCheckpoint(filepath=weights_fname,\n",
    "                        monitor=monitor_metric,\n",
    "                        verbose=Callback_Configurations.VERBOSE,\n",
    "                        save_best_only=True,\n",
    "                        save_weights_only=True), #True, False\n",
    "        \n",
    "        tf.keras.callbacks.TensorBoard(logdir)\n",
    "        \n",
    "                ]\n",
    "    return callbacks\n",
    "\n",
    "# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
    "\n",
    "def save_model(model, model_name):\n",
    "    \n",
    "    model_json = model.to_json()\n",
    "\n",
    "    with open(\"{}.json\".format(model_name), \"w\") as json_file:\n",
    "        json.dump(model_json, json_file)\n",
    "\n",
    "    model.save_weights(\"{}.h5\".format(model_name))\n",
    "    \n",
    "    print(\"\\nModel's weights are saved\")\n",
    "    \n",
    "# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "def plot_model_metrics(fit_model):\n",
    "\n",
    "    rcParams['figure.figsize'] = 10, 5\n",
    "\n",
    "    plt.plot(fit_model.history['sparse_categorical_accuracy'] , 'g') # acc\n",
    "    plt.plot(fit_model.history['val_sparse_categorical_accuracy'] , 'b') # val_acc\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    rcParams['figure.figsize'] = 10, 5\n",
    "\n",
    "    plt.plot(fit_model.history['loss'] , 'g')\n",
    "    plt.plot(fit_model.history['val_loss'] , 'b')\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "def plot_keras_history(history): #where history =  model.fit()\n",
    "    \"\"\"\n",
    "    \n",
    "    :param history: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    # the history object gives the metrics keys. \n",
    "    # we will store the metrics keys that are from the training sesion.\n",
    "    metrics_names = [key for key in history.history.keys() if not key.startswith('val_')]\n",
    "\n",
    "    for i, metric in enumerate(metrics_names):\n",
    "        \n",
    "        # getting the training values\n",
    "        metric_train_values = history.history.get(metric, [])\n",
    "        \n",
    "        # getting the validation values\n",
    "        metric_val_values = history.history.get(\"val_{}\".format(metric), [])\n",
    "\n",
    "        # As loss always exists as a metric we use it to find the \n",
    "        epochs = range(1, len(metric_train_values) + 1)\n",
    "        \n",
    "        # leaving extra spaces to allign with the validation text\n",
    "        training_text = \"   Training {}: {:.5f}\".format(metric,\n",
    "                                                        metric_train_values[-1])\n",
    "\n",
    "        # metric\n",
    "        plt.figure(i, figsize=(12, 6))\n",
    "\n",
    "        plt.plot(epochs,\n",
    "                 metric_train_values,\n",
    "                 'b',\n",
    "                 label=training_text)\n",
    "        \n",
    "        # if we validation metric exists, then plot that as well\n",
    "        if metric_val_values:\n",
    "            validation_text = \"Validation {}: {:.5f}\".format(metric,\n",
    "                                                             metric_val_values[-1])\n",
    "\n",
    "            plt.plot(epochs,\n",
    "                     metric_val_values,\n",
    "                     'g',\n",
    "                     label=validation_text)\n",
    "        \n",
    "        # add title, xlabel, ylabe, and legend\n",
    "        plt.title('Model Metric: {}'.format(metric))\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel(metric.title())\n",
    "        plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python Cell no.2\n",
    "------------------------------\n",
    "\n",
    "In this below python cell I keep track of the model parameters used to:\n",
    "\n",
    "* create the neural network model,\n",
    "* to fit the neural network,\n",
    "* to optimize the neural network.\n",
    "\n",
    "Storing the values of the parameters to a dictionary, I could then change dynamically the value of a parameter, rerun the neural model and then monitor the difference in the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network Logging parameters\n",
    "\n",
    "neural_network_parameters = {}\n",
    "optimizer_parameters = {}\n",
    "fit_parameters = {}\n",
    "\n",
    "# Create the neural network\n",
    "neural_network_parameters['embedding_dimension'] = 50\n",
    "neural_network_parameters['pool_size'] = None\n",
    "neural_network_parameters['padding'] = 'valid'\n",
    "neural_network_parameters['batch_size'] = 64\n",
    "neural_network_parameters['l2_regularization'] = 0.01\n",
    "neural_network_parameters['dropout_rate'] = 0.0\n",
    "neural_network_parameters['dense_activation'] = 'relu'\n",
    "neural_network_parameters['output_activation'] = 'sigmoid'\n",
    "neural_network_parameters['model_loss'] = \"binary_crossentropy\" #'sparse_categorical_crossentropy'\n",
    "neural_network_parameters['model_metric'] = \"accuracy\" #'sparse_categorical_accuracy'\n",
    "#--------------------------------------------------------------------------------------\n",
    "\n",
    "# Fit the neural network\n",
    "fit_parameters[\"steps_per_epoch\"] = len(partial_x_train_features)//neural_network_parameters['batch_size']\n",
    "fit_parameters[\"epoch\"] = 150\n",
    "fit_parameters[\"verbose_fit\"] = 0\n",
    "fit_parameters[\"batch_size_fit\"] = 64\n",
    "\n",
    "#---------------------------------------------------------------------------------------\n",
    "\n",
    "# Optimize the neural network\n",
    "\n",
    "# Optimizer: ADAM (version_1)\n",
    "optimizer_parameters['adam_learning_rate'] = 0.001\n",
    "optimizer_parameters['adam_beta_1'] = 0.99\n",
    "optimizer_parameters['adam_beta_2'] = 0.999\n",
    "optimizer_parameters['adam_amsgrad'] = False\n",
    "\n",
    "def optimizer_adam_v1():\n",
    "    \n",
    "    return keras.optimizers.Adam(learning_rate=optimizer_parameters['adam_learning_rate'], \n",
    "                                 beta_1=optimizer_parameters['adam_beta_1'], \n",
    "                                 beta_2=optimizer_parameters['adam_beta_2'], \n",
    "                                 amsgrad=optimizer_parameters['adam_amsgrad'])\n",
    "#---------------------------------------------------------------------------------------\n",
    "\n",
    "# Optimizer: ADAM (version_2)\n",
    "optimizer_parameters['steps_per_epoch'] = len(partial_x_train_features)//neural_network_parameters['batch_size']\n",
    "optimizer_parameters['lr_schedule_learning_rate'] = 0.01\n",
    "optimizer_parameters['lr_schedule_decay_steps'] = optimizer_parameters['steps_per_epoch']*1000\n",
    "optimizer_parameters['lr_schedule_decay_rate'] = 1\n",
    "optimizer_parameters['staircase'] = False\n",
    "\n",
    "#STEPS_PER_EPOCH = len(X_train_seq_features)//neural_network_parameters['batch_size'] #(512 = BATCH SIZE)\n",
    "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
    "    optimizer_parameters['lr_schedule_learning_rate'],\n",
    "    decay_steps=optimizer_parameters['lr_schedule_decay_steps'],\n",
    "    decay_rate=optimizer_parameters['lr_schedule_decay_rate'],\n",
    "    staircase=optimizer_parameters['staircase'])\n",
    "\n",
    "def optimizer_adam_v2():\n",
    "    \n",
    "    return keras.optimizers.Adam(lr_schedule)\n",
    "#---------------------------------------------------------------------------------------\n",
    "\n",
    "# Optimizer: SDG (version 1)\n",
    "\n",
    "optimizer_parameters['SGD_learning_rate'] = 0.01\n",
    "optimizer_parameters['SGD_decay'] = 1e-6\n",
    "optimizer_parameters['SGD_momentum'] = 0.9\n",
    "optimizer_parameters['SGD_nesterov'] = True\n",
    "\n",
    "def optimizer_SDG_v1():\n",
    "    \n",
    "    return keras.optimizers.SGD(lr=optimizer_parameters['SGD_learning_rate'],\n",
    "                                decay=optimizer_parameters['SGD_decay'],\n",
    "                                momentum=optimizer_parameters['SGD_momentum'],\n",
    "                                nesterov=optimizer_parameters['SGD_nesterov'])\n",
    "\n",
    "#---------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python Cell no.3\n",
    "------------------------------\n",
    "\n",
    "In the python cell below, I run MLFLOW program to train, fit, save and log the parameters, weights of the neural network.\n",
    "The code below is splitted into different parts indicated by short-name subtitle (<i>e.g import the pre-trained model</i>, <i>create the model structure</i>, <i>fit the model, etc.</i>)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"universal_sentence_encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer_2 (KerasLayer)   (None, 512)               147354880 \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 17)                1105      \n",
      "=================================================================\n",
      "Total params: 147,388,817\n",
      "Trainable params: 147,388,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "Pre-trained weights not found. Fitting from start\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_29:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_29:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_29:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_29:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0, accuracy:0.8912,  loss:nan,  val_accuracy:0.8924,  val_loss:nan,  \n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\spano\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py:1261: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current - self.min_delta, self.best):\n",
      "C:\\Users\\spano\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py:1020: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current, self.best):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[64,272,512] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[{{node universal_sentence_encoder/keras_layer_2/StatefulPartitionedCall/StatefulPartitionedCall/StatefulPartitionedCall/EncoderTransformer/Transformer/SparseTransformerEncode/Layer_5/SelfAttention/SparseMultiheadAttention/ComputeQKV/ScatterNd}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_distributed_function_455195]\n\nFunction call stack:\ndistributed_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-b752a18ed110>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx_val_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_val_plot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_val_actors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_val_reviews\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m                         \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_parameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"verbose_fit\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m                         callbacks=callback(\"universal_sentence_encoder\", model, logdir))\n\u001b[0m\u001b[0;32m     38\u001b[0m     \u001b[1;31m# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[1;32mc:\\users\\spano\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[64,272,512] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[{{node universal_sentence_encoder/keras_layer_2/StatefulPartitionedCall/StatefulPartitionedCall/StatefulPartitionedCall/EncoderTransformer/Transformer/SparseTransformerEncode/Layer_5/SelfAttention/SparseMultiheadAttention/ComputeQKV/ScatterNd}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_distributed_function_455195]\n\nFunction call stack:\ndistributed_function\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "    \n",
    "    # import the pre-trained model\n",
    "    model = \"https://tfhub.dev/google/universal-sentence-encoder-large/5\"\n",
    "    hub_layer = hub.KerasLayer(model, output_shape=[512], input_shape=[], dtype=tf.string, trainable=True)\n",
    "    \n",
    "    # create the model structure\n",
    "    model = tf.keras.Sequential(name=\"universal_sentence_encoder\")\n",
    "    model.add(hub_layer)\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(neural_network_parameters['batch_size'],\n",
    "                                    kernel_regularizer=regularizers.l2(neural_network_parameters['l2_regularization']),\n",
    "                                    activation=neural_network_parameters['dense_activation']))\n",
    "    model.add(tf.keras.layers.Dropout(neural_network_parameters['dropout_rate']))\n",
    "    model.add(tf.keras.layers.Dense(y_val.shape[1], activation=neural_network_parameters['output_activation']))\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    optimizer = optimizer_adam_v2()\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=neural_network_parameters['model_loss'],\n",
    "                  metrics=[neural_network_parameters['model_metric']])\n",
    "    \n",
    "    plot_model(model, to_file='universal_sentence_encoder.png')\n",
    "    \n",
    "    logdir = \".\\\\logs_test\\\\fit\\\\\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
    "    \n",
    "    # fit the model\n",
    "    history = model.fit([partial_x_train_features, partial_x_train_plot, partial_x_train_actors, partial_x_train_reviews],\n",
    "                        partial_y_train,\n",
    "                        epochs=fit_parameters[\"epoch\"],\n",
    "                        batch_size=fit_parameters[\"batch_size_fit\"],\n",
    "                        validation_data=([x_val_features, x_val_plot, x_val_actors, x_val_reviews], y_val),\n",
    "                        verbose=fit_parameters[\"verbose_fit\"],\n",
    "                        callbacks=callback(\"universal_sentence_encoder\", model, logdir))\n",
    "    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
    "    \n",
    "    # plot the model's progress per epoch\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    hist['epoch'] = history.epoch\n",
    "    hist['epoch']+= 1\n",
    "    hist.index += 1\n",
    "    print(\"\\nTable of training the keras text classification model\\n\")\n",
    "    print(tabulate(hist, headers='keys', tablefmt='psql'))\n",
    "    \n",
    "    hist.to_pickle(\".\\\\model_seven\\\\metrics_histogram_universal_sentence_encoder_08022020.pkl\")\n",
    "    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
    "    \n",
    "    # evaluate the model\n",
    "    model_evaluation = model.evaluate([test_bytes_list_features, test_bytes_list_plot, test_bytes_list_actors, test_bytes_list_reviews], test_label)\n",
    "\n",
    "    print('\\nTest Score:', model_evaluation[0])\n",
    "\n",
    "    print('\\nTest Accuracy:', model_evaluation[1])\n",
    "\n",
    "    print(model_evaluation)\n",
    "    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
    "    \n",
    "    # save the model\n",
    "    save_model(model, \"universal_sentence_encoder\")\n",
    "    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
    "\n",
    "    #plot_model_metrics(history)\n",
    "    plot_keras_history(history)\n",
    "    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
    "    \n",
    "    # Log model parameters and metrics\n",
    "    #neural_model params\n",
    "    mlflow.log_param(\"batch_size\", neural_network_parameters['batch_size'])\n",
    "    mlflow.log_param(\"l2_regularization\", neural_network_parameters['l2_regularization'])\n",
    "    mlflow.log_param(\"dropout_rate\", neural_network_parameters['dropout_rate'])\n",
    "    mlflow.log_param(\"dense_activation\", neural_network_parameters['dense_activation'])\n",
    "    mlflow.log_param(\"output_activation\",neural_network_parameters['output_activation'])\n",
    "    mlflow.log_param(\"model_loss\",neural_network_parameters['model_loss']) #takes any data type\n",
    "    mlflow.log_param(\"model_metric\",neural_network_parameters['model_metric'])\n",
    "    \n",
    "    #optimizer params\n",
    "    mlflow.log_param(\"lr_schedule_learning_rate\",optimizer_parameters['lr_schedule_learning_rate'])\n",
    "    mlflow.log_param(\"lr_schedule_decay_steps\",optimizer_parameters['lr_schedule_decay_steps'])\n",
    "    mlflow.log_param(\"lr_schedule_decay_rate\",optimizer_parameters['lr_schedule_decay_rate'])\n",
    "    mlflow.log_param(\"adam_amsgrad\",optimizer_parameters['staircase'])\n",
    "    \n",
    "    #fit_model params\n",
    "    #mlflow.log_param(\"steps_per_epoch\",fit_parameters['steps_per_epoch'])\n",
    "    mlflow.log_param(\"fit_epoch\",fit_parameters['epoch'])\n",
    "    mlflow.log_param(\"verbose_fit\",fit_parameters['verbose_fit'])\n",
    "    mlflow.log_param(\"batch_size_fit\",fit_parameters['batch_size_fit']) #in generl batch_size_fit = neurons batch size\n",
    "    \n",
    "    #logging the model metrics\n",
    "    mlflow.log_metric(\"model_validation_loss\",model_evaluation[0]) #take only floats/integers\n",
    "    mlflow.log_metric(\"model_validation_accuracy\",model_evaluation[1])\n",
    "    \n",
    "    mlflow.keras.log_model(model, \"universal_sentence_encoder\")\n",
    "\n",
    "#     mlflow.tensorflow.save_model(model, model_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use to yield probability distribution over the categories\n",
    "y_test_pred_probs = model.predict([test_bytes_list_features, test_bytes_list_plot, test_bytes_list_actors, test_bytes_list_reviews])\n",
    "y_test_pred_probs[0]\n",
    "\n",
    "y_test_predictions = (y_test_pred_probs>0.5).astype(int)\n",
    "y_test=test_label\n",
    "# y_predicted probabilities for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\".//model_seven//y_predictions_universal_sentence_encoder_08022020\", y_test_predictions)\n",
    "np.save(\".//model_seven//y_true_universal_sentence_encoder_08022020\", y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\spano\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\spano\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.87      0.89      1363\n",
      "           1       0.76      0.62      0.69       774\n",
      "           2       0.84      0.55      0.66       415\n",
      "           3       0.72      0.56      0.63       438\n",
      "           4       0.97      0.96      0.96      2835\n",
      "           5       0.92      0.67      0.78       988\n",
      "           6       0.99      0.89      0.94       782\n",
      "           7       0.98      0.97      0.97      4553\n",
      "           8       0.56      0.11      0.19       398\n",
      "           9       0.77      0.88      0.82      1020\n",
      "          10       0.00      0.00      0.00       205\n",
      "          11       0.68      0.50      0.58       502\n",
      "          12       0.93      0.85      0.89      1201\n",
      "          13       0.77      0.11      0.19       552\n",
      "          14       0.80      0.84      0.82      1270\n",
      "          15       0.81      0.27      0.40       332\n",
      "          16       0.95      0.16      0.27       263\n",
      "\n",
      "   micro avg       0.91      0.79      0.84     17891\n",
      "   macro avg       0.79      0.58      0.63     17891\n",
      "weighted avg       0.88      0.79      0.81     17891\n",
      " samples avg       0.89      0.82      0.83     17891\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "classification_report= classification_report(y_true=y_test,\n",
    "                                             y_pred=y_test_predictions)\n",
    "print(classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python Cell no.4\n",
    "------------------------------\n",
    "\n",
    "Store to dataframe the training and validation loss of the neural model. The result of the cell below is a dataframe which is then pickled locally. Having stored the dataframe locally I can then import all the dataframes related to the neural models and compare them to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Keras Model</th>\n",
       "      <th>Test Loss</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Google News 130Gb (with OOV tokens)</td>\n",
       "      <td>0.109344</td>\n",
       "      <td>0.968317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Keras Model  Test Loss  Test Accuracy\n",
       "0  Google News 130Gb (with OOV tokens)   0.109344       0.968317"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores = pd.DataFrame({'Keras Model':pd.Series(\"Universal Sentence Encoder\", dtype='str'),\n",
    "                         'Test Loss':pd.Series([model_evaluation[0]], dtype='float'),\n",
    "                         'Test Accuracy':pd.Series([model_evaluation[1]], dtype='float')})\n",
    "\n",
    "df_scores.to_pickle(\".\\\\model_seven\\\\universal_sentence_encoder_08022020.pkl\")\n",
    "\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python Cell no.5\n",
    "------------------------------\n",
    "\n",
    "Predict the genres tags on data the model never seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_genre_tags(indx, model):\n",
    "    \n",
    "    test_sequence_actors = np.asarray(test_bytes_list_actors[indx:indx+1])\n",
    "    \n",
    "    test_sequence_plot = np.asarray(test_bytes_list_plot[indx:indx+1])\n",
    "    \n",
    "    test_sequence_features = np.asarray(test_bytes_list_features[indx:indx+1])\n",
    "    \n",
    "    test_sequence_reviews = test_bytes_list_reviews[indx:indx+1]\n",
    "    \n",
    "    text_prediction = model.predict([np.asarray(test_sequence_actors), \n",
    "                                     np.asarray(test_sequence_plot), \n",
    "                                     np.asarray(test_sequence_features), \n",
    "                                     np.asarray(test_sequence_reviews)])\n",
    "    print(text_prediction[0])\n",
    "    \n",
    "    [float(i) for i in text_prediction[0]]\n",
    "    \n",
    "    tag_probabilities = text_prediction[0][np.argsort(text_prediction[0])[-3:]]\n",
    "    \n",
    "    indexes = np.argsort(text_prediction[0])[::-1][:3]\n",
    "\n",
    "    predicted_tags = []\n",
    "    \n",
    "    for i, tag in enumerate(genres_list):\n",
    "        if i in indexes:\n",
    "            predicted_tags.append(genres_list[i])\n",
    "    \n",
    "    return predicted_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly saved numbers to make predictions: [1796, 2127, 6420, 7970, 6925]\n"
     ]
    }
   ],
   "source": [
    "random_numbers = random.sample(range(1, test_label.shape[0]), 5)\n",
    "\n",
    "save_index_of_numbers = random_numbers\n",
    "\n",
    "print(\"Randomly saved numbers to make predictions: {}\".format(save_index_of_numbers))\n",
    "\n",
    "with open('genres_list_08022020.pkl', 'rb') as handle:\n",
    "    genres_list = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type list).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-cf637be04acf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m df_predictions = pd.DataFrame({'Movie Title':pd.Series([X_test_actors['title'].iloc[save_index_of_numbers[0]]], dtype='str'),\n\u001b[1;32m----> 4\u001b[1;33m                                \u001b[1;34m'Predicted Genre tags'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpredict_genre_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_index_of_numbers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'str'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m                                'Real Genre tags':pd.Series([X_test_actors['genres'].iloc[save_index_of_numbers[0]]], dtype='str')})\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-45-7162d9fb86d6>\u001b[0m in \u001b[0;36mpredict_genre_tags\u001b[1;34m(indx, model)\u001b[0m\n\u001b[0;32m     14\u001b[0m                                      \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_sequence_plot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m                                      \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_sequence_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m                                      np.asarray(test_sequence_reviews)])\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_prediction\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1011\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1012\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1013\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m   1014\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1015\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, model, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    496\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m         \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 498\u001b[1;33m         workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)\n\u001b[0m\u001b[0;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[1;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    424\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 426\u001b[1;33m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    427\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madapter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m       \u001b[0muse_sample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtotal_samples\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[1;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    704\u001b[0m       \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    705\u001b[0m       \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 706\u001b[1;33m       use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    708\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    355\u001b[0m     \u001b[0mindices_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflat_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslice_batch_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m     \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mslice_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"batch\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36mslice_inputs\u001b[1;34m(self, indices_dataset, inputs)\u001b[0m\n\u001b[0;32m    381\u001b[0m     dataset = dataset_ops.DatasetV2.zip((\n\u001b[0;32m    382\u001b[0m         \u001b[0mindices_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 383\u001b[1;33m         \u001b[0mdataset_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDatasetV2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    384\u001b[0m     ))\n\u001b[0;32m    385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mfrom_tensors\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    564\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m     \"\"\"\n\u001b[1;32m--> 566\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    567\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    568\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, element)\u001b[0m\n\u001b[0;32m   2763\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2764\u001b[0m     \u001b[1;34m\"\"\"See `Dataset.from_tensors()` for details.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2765\u001b[1;33m     \u001b[0melement\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2766\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_structure\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_spec_from_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2767\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\data\\util\\structure.py\u001b[0m in \u001b[0;36mnormalize_element\u001b[1;34m(element)\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m           normalized_components.append(\n\u001b[1;32m--> 113\u001b[1;33m               ops.convert_to_tensor(t, name=\"component_%d\" % i))\n\u001b[0m\u001b[0;32m    114\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalized_components\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1313\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1314\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\framework\\tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m   \u001b[1;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[1;31m# Unused.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    256\u001b[0m   \"\"\"\n\u001b[0;32m    257\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[1;32m--> 258\u001b[1;33m                         allow_broadcast=True)\n\u001b[0m\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    264\u001b[0m   \u001b[0mctx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 266\u001b[1;33m     \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    267\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m     94\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m   \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type list)."
     ]
    }
   ],
   "source": [
    "# CHECK THIS ERROR WITH Professor Louridas!\n",
    "\n",
    "df_predictions = pd.DataFrame({'Movie Title':pd.Series([X_test_actors['title'].iloc[save_index_of_numbers[0]]], dtype='str'),\n",
    "                               'Predicted Genre tags':pd.Series([predict_genre_tags(save_index_of_numbers[0], model)], dtype='str'),\n",
    "                               'Real Genre tags':pd.Series([X_test_actors['genres'].iloc[save_index_of_numbers[0]]], dtype='str')})\n",
    "\n",
    "for i in range(len(save_index_of_numbers[0:])):\n",
    "\n",
    "    df_predictions = df_predictions.append({'Movie Title' : X_test_features['title'].iloc[save_index_of_numbers[i]], \n",
    "                                            'Predicted Genre tags' : predict_genre_tags(save_index_of_numbers[i], model),\n",
    "                                            'Real Genre tags': X_test_features['genres'].iloc[save_index_of_numbers[i]]} , ignore_index=True)\n",
    "\n",
    "df_predictions.drop(df_predictions.index[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
