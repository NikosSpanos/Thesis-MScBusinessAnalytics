{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3.2 - Model 1: Multi-Input Keras neural model (latest changes on 08.02.2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import standard libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from tabulate import tabulate\n",
    "import re\n",
    "\n",
    "import random\n",
    "\n",
    "# Module to serialize the content produced from the execution of the code\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Module to monitor the progress of a python for loop\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "# Module to manipulate text in python - NLTK package\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Module to compute word vectorizers and compute the cosine distance\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "import string\n",
    "import itertools\n",
    "\n",
    "# from IPython.core.display import display, HTML\n",
    "# display(HTML(\"<style>.container { width:70% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Tensorflow-Keras Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  2.1.0\n",
      "Version:  2.1.0\n",
      "Eager mode:  True\n",
      "Hub version:  0.7.0\n",
      "GPU is NOT AVAILABLE\n",
      "Wall time: 3.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from time import time\n",
    "\n",
    "#--------------------------------------------------------------\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "#---------------------------------------------------------------\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "\n",
    "import pydot\n",
    "import pydotplus\n",
    "import graphviz\n",
    "\n",
    "from IPython.display import SVG\n",
    "from tensorflow.keras.utils import model_to_dot\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import model_from_json\n",
    "import json\n",
    "\n",
    "# Import ML FLow\n",
    "import mlflow.tensorflow\n",
    "import mlflow.pyfunc\n",
    "from tensorflow.keras import regularizers\n",
    "import datetime\n",
    "\n",
    "# Import TensorBoard\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.plots as tfplots\n",
    "import tensorflow_docs.modeling as tfmodel\n",
    "from tensorflow.keras import regularizers\n",
    "# from tensorboard import default\n",
    "# from tensorboard import program\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "import bert\n",
    "from bert import tokenization\n",
    "from bert.tokenization import FullTokenizer\n",
    "\n",
    "#Visualize Model\n",
    "\n",
    "def visualize_model(model):\n",
    "    return SVG(model_to_dot(model, show_shapes= True, show_layer_names=True, dpi=65).create(prog='dot', format='svg'))\n",
    "\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "from packaging import version\n",
    "\n",
    "print(\"TensorFlow version: \", tf.__version__)\n",
    "assert version.parse(tf.__version__).release[0] >= 2, \\\n",
    "    \"This notebook requires TensorFlow 2.0 or above.\"\n",
    "\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"Hub version: \", hub.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the data already tokenized and transformed from Part 3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 80-20 split - Non-balanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train data inputs have been loaded!\n",
      "\n",
      "X_test data inputs have been loaded!\n",
      "\n",
      "y_train & y_test have been loaded!\n",
      "\n",
      "X_train_seq_actors shape:(39298, 17)\n",
      "X_train_seq_plot shape:(39298, 23)\n",
      "X_train_seq_features shape:(39298, 60)\n",
      "X_train_seq_reviews shape:(39298, 2067)\n",
      "\n",
      "X_test_seq_actors shape:(9825, 17)\n",
      "X_test_seq_plot shape:(9825, 23)\n",
      "X_test_seq_features shape:(9825, 60)\n",
      "X_test_seq_reviews shape:(9825, 2067)\n",
      "\n",
      "y_train shape:(39298, 17)\n",
      "y_test shape:(9825, 17)\n"
     ]
    }
   ],
   "source": [
    "X_train_seq_actors=np.load(\"C:\\\\Users\\\\spano\\\\Desktop\\\\GitHub-Thesis\\\\models_text_classification\\\\80-20 split_non-balanced\\\\x_train_seq_actors_80-20_non-balanced_07022020.npy\")\n",
    "X_train_seq_plot=np.load(\"C:\\\\Users\\\\spano\\\\Desktop\\\\GitHub-Thesis\\\\models_text_classification\\\\80-20 split_non-balanced\\\\x_train_seq_plot_80-20_non-balanced_07022020.npy\")\n",
    "X_train_seq_features=np.load(\"C:\\\\Users\\\\spano\\\\Desktop\\\\GitHub-Thesis\\\\models_text_classification\\\\80-20 split_non-balanced\\\\x_train_seq_features_80-20_non-balanced_07022020.npy\")\n",
    "X_train_seq_reviews=np.load(\"C:\\\\Users\\\\spano\\\\Desktop\\\\GitHub-Thesis\\\\models_text_classification\\\\80-20 split_non-balanced\\\\x_train_seq_reviews_80-20_non-balanced_07022020.npy\")\n",
    "\n",
    "print(\"X_train data inputs have been loaded!\\n\")\n",
    "\n",
    "X_test_seq_actors=np.load(\"C:\\\\Users\\\\spano\\\\Desktop\\\\GitHub-Thesis\\\\models_text_classification\\\\80-20 split_non-balanced\\\\x_test_seq_actors_80-20_non-balanced_07022020.npy\")\n",
    "X_test_seq_plot=np.load(\"C:\\\\Users\\\\spano\\\\Desktop\\\\GitHub-Thesis\\\\models_text_classification\\\\80-20 split_non-balanced\\\\x_test_seq_plot_80-20_non-balanced_07022020.npy\")\n",
    "X_test_seq_features=np.load(\"C:\\\\Users\\\\spano\\\\Desktop\\\\GitHub-Thesis\\\\models_text_classification\\\\80-20 split_non-balanced\\\\x_test_seq_features_80-20_non-balanced_07022020.npy\")\n",
    "X_test_seq_reviews=np.load(\"C:\\\\Users\\\\spano\\\\Desktop\\\\GitHub-Thesis\\\\models_text_classification\\\\80-20 split_non-balanced\\\\x_test_seq_reviews_80-20_non-balanced_07022020.npy\")\n",
    "\n",
    "print(\"X_test data inputs have been loaded!\\n\")\n",
    "\n",
    "y_train=np.load(\"C:\\\\Users\\\\spano\\\\Desktop\\\\GitHub-Thesis\\\\models_text_classification\\\\80-20 split_non-balanced\\\\y_train_80-20_non-balanced_07022020.npy\")\n",
    "y_test=np.load(\"C:\\\\Users\\\\spano\\\\Desktop\\\\GitHub-Thesis\\\\models_text_classification\\\\80-20 split_non-balanced\\\\y_test_80-20_non-balanced_07022020.npy\")\n",
    "\n",
    "print(\"y_train & y_test have been loaded!\\n\")\n",
    "\n",
    "print(\"X_train_seq_actors shape:{}\".format(X_train_seq_actors.shape))\n",
    "print(\"X_train_seq_plot shape:{}\".format(X_train_seq_plot.shape))\n",
    "print(\"X_train_seq_features shape:{}\".format(X_train_seq_features.shape))\n",
    "print(\"X_train_seq_reviews shape:{}\\n\".format(X_train_seq_reviews.shape))\n",
    "\n",
    "print(\"X_test_seq_actors shape:{}\".format(X_test_seq_actors.shape))\n",
    "print(\"X_test_seq_plot shape:{}\".format(X_test_seq_plot.shape))\n",
    "print(\"X_test_seq_features shape:{}\".format(X_test_seq_features.shape))\n",
    "print(\"X_test_seq_reviews shape:{}\\n\".format(X_test_seq_reviews.shape))\n",
    "\n",
    "print(\"y_train shape:{}\".format(y_train.shape))\n",
    "print(\"y_test shape:{}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ML-FLOW approach (contrary to TensorBoard) - <i> 15.01.2020 </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "# %reload_text tensorboard\n",
    "\n",
    "logdir=\".\\\\logs\\\\fit\\\\\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
    "\n",
    "# Callback function with early stopping to avodid overfit\n",
    "\n",
    "class Callback_Configurations():\n",
    "    \n",
    "    MONITOR_METRIC = 'val_loss'\n",
    "    MINIMUM_DELTA = 1\n",
    "    PATIENCE = 10\n",
    "    VERBOSE = 0\n",
    "    MODE = 'min'\n",
    "    \n",
    "def callback(saved_model, model, logdir):\n",
    "    \n",
    "    weights_fname = '{}.h5'.format(saved_model)\n",
    "\n",
    "    try:\n",
    "        with open('{}.json'.format(save_model),'r') as f:\n",
    "            model_json = json.load(f)\n",
    "        \n",
    "        model = model_from_json(model_json)\n",
    "        \n",
    "        model.load_weights('{}').format(weights_fname)\n",
    "\n",
    "    except:\n",
    "        print('\\nPre-trained weights not found. Fitting from start')\n",
    "        pass\n",
    "\n",
    "    monitor_metric = Callback_Configurations.MONITOR_METRIC\n",
    "    \n",
    "    callbacks = [\n",
    "        tfmodel.EpochDots(),\n",
    "        \n",
    "        EarlyStopping(monitor=monitor_metric,\n",
    "                      min_delta=Callback_Configurations.MINIMUM_DELTA,\n",
    "                      patience=Callback_Configurations.PATIENCE,\n",
    "                      verbose=Callback_Configurations.VERBOSE,\n",
    "                      mode=Callback_Configurations.MODE,\n",
    "                      restore_best_weights=True),\n",
    "\n",
    "        ModelCheckpoint(filepath=weights_fname,\n",
    "                        monitor=monitor_metric,\n",
    "                        verbose=Callback_Configurations.VERBOSE,\n",
    "                        save_best_only=True,\n",
    "                        save_weights_only=True), #True, False\n",
    "        \n",
    "        tf.keras.callbacks.TensorBoard(logdir)\n",
    "        \n",
    "]\n",
    "    return callbacks\n",
    "\n",
    "# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
    "\n",
    "# Function to fit the keras multy input model\n",
    "\n",
    "def fit_keras_multy_input(model, \n",
    "                          x_train_seq_actors, \n",
    "                          x_train_seq_plot, \n",
    "                          x_train_seq_features,\n",
    "                          x_train_seq_reviews,\n",
    "                          x_test_seq_actors, \n",
    "                          x_test_seq_plot, \n",
    "                          x_test_seq_features,\n",
    "                          x_test_seq_reviews,\n",
    "                          y_train, \n",
    "                          y_test,\n",
    "                          callbacks,\n",
    "                          steps_per_epoch,\n",
    "                          epoch,\n",
    "                          verbose_fit,\n",
    "                          batch_size_fit):\n",
    "    \n",
    "    s = time()\n",
    "\n",
    "    fit_model = model.fit([x_train_seq_actors, x_train_seq_plot, x_train_seq_features, x_train_seq_reviews], y_train,\n",
    "                          steps_per_epoch = steps_per_epoch,\n",
    "                          epochs=epoch,\n",
    "                          verbose=verbose_fit,\n",
    "                          batch_size=batch_size_fit,\n",
    "                          validation_data=([x_test_seq_actors, x_test_seq_plot, x_test_seq_features, x_test_seq_reviews], y_test),\n",
    "                          callbacks=callbacks) #(callbacks)\n",
    "\n",
    "    duration = time() - s\n",
    "    print(\"\\nTraining time finished. Duration {} secs\".format(duration))\n",
    "    \n",
    "    return fit_model\n",
    "\n",
    "# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
    "\n",
    "def save_model(model, model_name):\n",
    "    \n",
    "    model_json = model.to_json()\n",
    "\n",
    "    with open(\"{}.json\".format(model_name), \"w\") as json_file:\n",
    "        json.dump(model_json, json_file)\n",
    "\n",
    "    model.save_weights(\"{}.h5\".format(model_name))\n",
    "    \n",
    "    print(\"\\nModel's weights are saved\")\n",
    "    \n",
    "# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
    "\n",
    "# function to plot the model metrics (deprecated)\n",
    "\n",
    "def plot_model_metrics(fit_model):\n",
    "\n",
    "    rcParams['figure.figsize'] = 12, 6\n",
    "\n",
    "    plt.plot(fit_model.history['accuracy'] , 'g') # acc\n",
    "    plt.plot(fit_model.history['val_accuracy'] , 'b') # val_acc\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    rcParams['figure.figsize'] = 12, 6\n",
    "\n",
    "    plt.plot(fit_model.history['loss'] , 'g')\n",
    "    plt.plot(fit_model.history['val_loss'] , 'b')\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
    "\n",
    "# alternative function to plot the model metrics (used)\n",
    "\n",
    "def plot_keras_history(history): #where history =  model.fit()\n",
    "    \"\"\"\n",
    "    \n",
    "    :param history: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    # the history object gives the metrics keys. \n",
    "    # we will store the metrics keys that are from the training sesion.\n",
    "    metrics_names = [key for key in history.history.keys() if not key.startswith('val_')]\n",
    "\n",
    "    for i, metric in enumerate(metrics_names):\n",
    "        \n",
    "        # getting the training values\n",
    "        metric_train_values = history.history.get(metric, [])\n",
    "        \n",
    "        # getting the validation values\n",
    "        metric_val_values = history.history.get(\"val_{}\".format(metric), [])\n",
    "\n",
    "        # As loss always exists as a metric we use it to find the \n",
    "        epochs = range(1, len(metric_train_values) + 1)\n",
    "        \n",
    "        # leaving extra spaces to allign with the validation text\n",
    "        training_text = \"   Training {}: {:.5f}\".format(metric,\n",
    "                                                        metric_train_values[-1])\n",
    "\n",
    "        # metric\n",
    "        plt.figure(i, figsize=(12, 6))\n",
    "\n",
    "        plt.plot(epochs,\n",
    "                 metric_train_values,\n",
    "                 'b',\n",
    "                 label=training_text)\n",
    "        \n",
    "        # if we validation metric exists, then plot that as well\n",
    "        if metric_val_values:\n",
    "            validation_text = \"Validation {}: {:.5f}\".format(metric,\n",
    "                                                             metric_val_values[-1])\n",
    "\n",
    "            plt.plot(epochs,\n",
    "                     metric_val_values,\n",
    "                     'g',\n",
    "                     label=validation_text)\n",
    "        \n",
    "        # add title, xlabel, ylabe, and legend\n",
    "        plt.title('Model Metric: {}'.format(metric))\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel(metric.title())\n",
    "        plt.legend()\n",
    "    \n",
    "    fig1 = plt.gcf()\n",
    "    #plt.savefig('multi-input-keras.png')\n",
    "    plt.show()\n",
    "    plt.draw()\n",
    "    fig1.savefig('multi-input-keras.png', dpi=100)\n",
    "\n",
    "# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
    "\n",
    "# Create function that will get as input a dataframe with the metrics (validation, accuracy) and create a plot per epoch\n",
    "# Proposed modules: seaborn, plotly, matplolib.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network Structure\n",
    "\n",
    "neural_network_parameters = {}\n",
    "optimizer_parameters = {}\n",
    "fit_parameters = {}\n",
    "\n",
    "neural_network_parameters['embedding_dimension'] = 50 #Grid-search on that value\n",
    "neural_network_parameters['pool_size'] = None\n",
    "neural_network_parameters['padding'] = 'valid'\n",
    "neural_network_parameters['batch_size'] = 64 #Grid-search on that value\n",
    "neural_network_parameters['l2_regularization'] = 0.01 #Grid-search on that value\n",
    "neural_network_parameters['dropout_rate'] = 0.0 #Grid-search on that value\n",
    "neural_network_parameters['dense_activation'] = 'relu'\n",
    "neural_network_parameters['output_activation'] = 'sigmoid' #softmax, sigmoid\n",
    "neural_network_parameters['number_target_variables'] = len(y_train[0].tolist())\n",
    "\n",
    "#It’s important to notice, that we use a sigmoid activation function with a multiclass output-layer. \n",
    "#The sigmoid gives us independent propabilities for each class. So DON’T use softmax here!\n",
    "\n",
    "neural_network_parameters['model_loss'] = 'binary_crossentropy' #sparse_categorical_crossentropy, binary_crossentropy, categorical_crossentropy\n",
    "neural_network_parameters['model_metric'] = 'accuracy' #sparse_categorical_accuracy, accuracy\n",
    "\n",
    "#--------------------------------------------------------------------------------------\n",
    "\n",
    "fit_parameters[\"steps_per_epoch\"] = len(X_train_seq_features)//neural_network_parameters['batch_size']\n",
    "fit_parameters[\"epoch\"] = 150\n",
    "fit_parameters[\"verbose_fit\"] = 0\n",
    "fit_parameters[\"batch_size_fit\"] = 64 #Grid-search on that value\n",
    "\n",
    "#---------------------------------------------------------------------------------------\n",
    "\n",
    "# Optimizer: ADAM (version_1)\n",
    "\n",
    "optimizer_parameters['adam_learning_rate'] = 0.001\n",
    "optimizer_parameters['adam_beta_1'] = 0.9\n",
    "optimizer_parameters['adam_beta_2'] = 0.999\n",
    "optimizer_parameters['adam_amsgrad'] = False\n",
    "\n",
    "def optimizer_adam_v1():\n",
    "    \n",
    "    return keras.optimizers.Adam(learning_rate=optimizer_parameters['adam_learning_rate'], \n",
    "                                 beta_1=optimizer_parameters['adam_beta_1'], \n",
    "                                 beta_2=optimizer_parameters['adam_beta_2'], \n",
    "                                 amsgrad=optimizer_parameters['adam_amsgrad'])\n",
    "#---------------------------------------------------------------------------------------\n",
    "\n",
    "# Optimizer: ADAM (version_2)\n",
    "\n",
    "# lr_schedule_learning_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "# lr_schedule_decay_rate = [1, 2, 3, 4]\n",
    "\n",
    "optimizer_parameters['steps_per_epoch'] = len(X_train_seq_features)//neural_network_parameters['batch_size']\n",
    "# Steps per epoch...fine tune\n",
    "optimizer_parameters['lr_schedule_learning_rate'] = 0.01 #Grid-search on that value\n",
    "optimizer_parameters['lr_schedule_decay_steps'] = optimizer_parameters['steps_per_epoch']*1000\n",
    "optimizer_parameters['lr_schedule_decay_rate'] = 1 #Grid-search on that value\n",
    "optimizer_parameters['staircase'] = False\n",
    "\n",
    "#STEPS_PER_EPOCH = len(X_train_seq_features)//neural_network_parameters['batch_size'] #(512 = BATCH SIZE)\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
    "    optimizer_parameters['lr_schedule_learning_rate'],\n",
    "    decay_steps=optimizer_parameters['lr_schedule_decay_steps'],\n",
    "    decay_rate=optimizer_parameters['lr_schedule_decay_rate'],\n",
    "    staircase=optimizer_parameters['staircase'])\n",
    "\n",
    "def optimizer_adam_v2():\n",
    "    \n",
    "    return keras.optimizers.Adam(lr_schedule)\n",
    "#---------------------------------------------------------------------------------------\n",
    "\n",
    "# Optimizer: SDG (version 1)\n",
    "\n",
    "optimizer_parameters['SGD_learning_rate'] = 0.01\n",
    "optimizer_parameters['SGD_decay'] = 1e-6\n",
    "optimizer_parameters['SGD_momentum'] = 0.9\n",
    "optimizer_parameters['SGD_nesterov'] = True\n",
    "\n",
    "def optimizer_SDG_v1():\n",
    "    \n",
    "    return keras.optimizers.SGD(lr=optimizer_parameters['SGD_learning_rate'],\n",
    "                                decay=optimizer_parameters['SGD_decay'],\n",
    "                                momentum=optimizer_parameters['SGD_momentum'],\n",
    "                                nesterov=optimizer_parameters['SGD_nesterov'])\n",
    "\n",
    "#---------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_multy_classification_model_v4(maxlen_actors, maxlen_plot, maxlen_features, optimizer_version = None):\n",
    "    \n",
    "    sentenceLength_actors = maxlen_actors\n",
    "    vocab_size_frequent_words_actors = 20001\n",
    "    \n",
    "    sentenceLength_plot = maxlen_plot\n",
    "    vocab_size_frequent_words_plot = 17501\n",
    "    \n",
    "    sentenceLength_features = maxlen_features\n",
    "    vocab_size_frequent_words_features = 20001\n",
    "    \n",
    "    sentenceLength_reviews = maxlen_reviews\n",
    "    vocab_size_frequent_words_reviews = 40001\n",
    "    \n",
    "    model = keras.Sequential(name='MultyInput_Keras_Classification_model')\n",
    "    \n",
    "    actors = keras.Input(shape=(sentenceLength_actors,), name='actors_input')\n",
    "    plot = keras.Input(shape=(sentenceLength_plot,), name='plot_input')\n",
    "    features = keras.Input(shape=(sentenceLength_features,), name='features_input')\n",
    "    reviews = keras.Input(shape=(sentenceLength_reviews,), name='reviews_input')\n",
    "    \n",
    "    emb1 = layers.Embedding(input_dim = vocab_size_frequent_words_actors + 1,\n",
    "                            output_dim = neural_network_parameters['embedding_dimension'],\n",
    "                            embeddings_initializer = 'uniform', \n",
    "                            mask_zero = False,\n",
    "                            input_length = sentenceLength_actors,\n",
    "                            name=\"actors_embedding_layer\")(actors)\n",
    "    \n",
    "    encoded_layer1 = layers.GlobalMaxPooling1D(name=\"globalmaxpooling1\")(emb1)\n",
    "    \n",
    "    emb2 = layers.Embedding(input_dim = vocab_size_frequent_words_plot + 1,\n",
    "                            output_dim = neural_network_parameters['embedding_dimension'],\n",
    "                            embeddings_initializer = 'uniform',\n",
    "                            mask_zero = False,\n",
    "                            input_length = sentenceLength_plot,\n",
    "                            name=\"plot_embedding_layer\")(plot)\n",
    "    \n",
    "    encoded_layer2 = layers.GlobalMaxPooling1D(name=\"globalmaxpooling2\")(emb2)\n",
    "\n",
    "    emb3 = layers.Embedding(input_dim = vocab_size_frequent_words_features + 1,\n",
    "                            output_dim = neural_network_parameters['embedding_dimension'],\n",
    "                            embeddings_initializer = 'uniform',\n",
    "                            mask_zero = False,\n",
    "                            input_length = sentenceLength_features,\n",
    "                            name=\"features_embedding_layer\")(features)\n",
    "    \n",
    "    encoded_layer3 = layers.GlobalMaxPooling1D(name=\"globalmaxpooling3\")(emb3)\n",
    "    \n",
    "    emb4 = layers.Embedding(input_dim = vocab_size_frequent_words_reviews + 1,\n",
    "                            output_dim = neural_network_parameters['embedding_dimension'],\n",
    "                            embeddings_initializer = 'uniform',\n",
    "                            mask_zero = False,\n",
    "                            input_length = sentenceLength_reviews,\n",
    "                            name=\"reviews_embedding_layer\")(reviews)\n",
    "    \n",
    "    encoded_layer4 = layers.GlobalMaxPooling1D(name=\"globalmaxpooling4\")(emb4)\n",
    "    \n",
    "    merged = layers.concatenate([encoded_layer1, encoded_layer2, encoded_layer3, encoded_layer4], axis=-1)\n",
    "\n",
    "    dense_layer_1 = layers.Dense(neural_network_parameters['batch_size'], \n",
    "                                 kernel_regularizer=regularizers.l2(neural_network_parameters['l2_regularization']),\n",
    "                                 activation=neural_network_parameters['dense_activation'],\n",
    "                                 name=\"1st_dense_layer\")(merged)\n",
    "    layers.Dropout(neural_network_parameters['dropout_rate'])(dense_layer_1)\n",
    "    \n",
    "    dense_layer_2 = layers.Dense(neural_network_parameters['batch_size'], \n",
    "                                 kernel_regularizer=regularizers.l2(neural_network_parameters['l2_regularization']),\n",
    "                                 activation=neural_network_parameters['dense_activation'],\n",
    "                                 name='2nd_dense_layer')(dense_layer_1)\n",
    "    layers.Dropout(neural_network_parameters['dropout_rate'])(dense_layer_2)\n",
    "    \n",
    "    output_layer = layers.Dense(neural_network_parameters['number_target_variables'], activation=neural_network_parameters['output_activation'],\n",
    "                                name='output_layer')(dense_layer_2)\n",
    "    \n",
    "    model = keras.Model(inputs=[actors, plot, features, reviews], outputs=output_layer)\n",
    "    \n",
    "    print(model.output_shape)\n",
    "\n",
    "    print(model.summary())\n",
    "    \n",
    "    # Version_1 of Adam\n",
    "    if optimizer_version is None:\n",
    "        \n",
    "        optimizer = optimizer_adam_v1()\n",
    "    \n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=neural_network_parameters['model_loss'],\n",
    "                  metrics=[neural_network_parameters['model_metric']])\n",
    "    \n",
    "    plot_model(model, to_file='multy_input_keras_model.png')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_multy_classification_model_v5(maxlen_actors, maxlen_plot, maxlen_features, maxlen_reviews, optimizer_version = None):\n",
    "    \n",
    "    sentenceLength_actors = maxlen_actors\n",
    "    vocab_size_frequent_words_actors = 20001\n",
    "    \n",
    "    sentenceLength_plot = maxlen_plot\n",
    "    vocab_size_frequent_words_plot = 17501\n",
    "    \n",
    "    sentenceLength_features = maxlen_features\n",
    "    vocab_size_frequent_words_features = 20001\n",
    "    \n",
    "    sentenceLength_reviews = maxlen_reviews\n",
    "    vocab_size_frequent_words_reviews = 40001\n",
    "    \n",
    "    model = keras.Sequential(name='MultyInput_Keras_Classification_model')\n",
    "    \n",
    "    actors = keras.Input(shape=(sentenceLength_actors,), name='actors_input')\n",
    "    plot = keras.Input(shape=(sentenceLength_plot,), name='plot_input')\n",
    "    features = keras.Input(shape=(sentenceLength_features,), name='features_input')\n",
    "    reviews = keras.Input(shape=(sentenceLength_reviews,), name='reviews_input')\n",
    "    \n",
    "    emb1 = layers.Embedding(input_dim = vocab_size_frequent_words_actors + 1,\n",
    "                            output_dim = neural_network_parameters['embedding_dimension'],\n",
    "                            embeddings_initializer = 'uniform', \n",
    "                            mask_zero = True,\n",
    "                            input_length = sentenceLength_actors,\n",
    "                            name=\"actors_embedding_layer\")(actors)\n",
    "    \n",
    "    encoded_layer1 = layers.GlobalMaxPooling1D(name=\"globalmaxpooling1\")(emb1)\n",
    "    \n",
    "    emb2 = layers.Embedding(input_dim = vocab_size_frequent_words_plot + 1,\n",
    "                            output_dim = neural_network_parameters['embedding_dimension'],\n",
    "                            embeddings_initializer = 'uniform',\n",
    "                            mask_zero = True,\n",
    "                            input_length = sentenceLength_plot,\n",
    "                            name=\"plot_embedding_layer\")(plot)\n",
    "    \n",
    "    encoded_layer2 = layers.GlobalMaxPooling1D(name=\"globalmaxpooling2\")(emb2)\n",
    "\n",
    "    emb3 = layers.Embedding(input_dim = vocab_size_frequent_words_features + 1,\n",
    "                            output_dim = neural_network_parameters['embedding_dimension'],\n",
    "                            embeddings_initializer = 'uniform',\n",
    "                            mask_zero = True,\n",
    "                            input_length = sentenceLength_features,\n",
    "                            name=\"features_embedding_layer\")(features)\n",
    "    \n",
    "    encoded_layer3 = layers.GlobalMaxPooling1D(name=\"globalmaxpooling3\")(emb3)\n",
    "    \n",
    "    emb4 = layers.Embedding(input_dim = vocab_size_frequent_words_reviews + 1,\n",
    "                            output_dim = neural_network_parameters['embedding_dimension'],\n",
    "                            embeddings_initializer = 'uniform',\n",
    "                            mask_zero = True,\n",
    "                            input_length = sentenceLength_reviews,\n",
    "                            name=\"reviews_embedding_layer\")(reviews)\n",
    "    \n",
    "    encoded_layer4 = layers.GlobalMaxPooling1D(name=\"globalmaxpooling4\")(emb4) #2D for images\n",
    "    \n",
    "    merged = layers.concatenate([encoded_layer1, encoded_layer2, encoded_layer3, encoded_layer4], axis=-1)\n",
    "\n",
    "    dense_layer_1 = layers.Dense(neural_network_parameters['batch_size'], \n",
    "                                 #kernel_regularizer=regularizers.l2(neural_network_parameters['l2_regularization']),\n",
    "                                 activation=neural_network_parameters['dense_activation'],\n",
    "                                 name=\"1st_dense_layer\")(merged)\n",
    "    \n",
    "    dense_layer_2 = layers.Dense(neural_network_parameters['batch_size'], \n",
    "                                 #kernel_regularizer=regularizers.l2(neural_network_parameters['l2_regularization']),\n",
    "                                 activation=neural_network_parameters['dense_activation'],\n",
    "                                 name='2nd_dense_layer')(dense_layer_1)\n",
    "    \n",
    "    output_layer = layers.Dense(neural_network_parameters['number_target_variables'], activation=neural_network_parameters['output_activation'],\n",
    "                                name='output_layer')(dense_layer_2)\n",
    "    \n",
    "    model = keras.Model(inputs=[actors, plot, features, reviews], outputs=output_layer)\n",
    "    \n",
    "    print(model.output_shape)\n",
    "\n",
    "    print(model.summary())\n",
    "    \n",
    "    # Version_1 of Adam\n",
    "    if optimizer_version is None:\n",
    "        \n",
    "        optimizer = optimizer_adam_v1()\n",
    "    \n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=neural_network_parameters['model_loss'],\n",
    "                  metrics=[neural_network_parameters['model_metric']])\n",
    "    \n",
    "    plot_model(model, to_file='multy_input_keras_model.png')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_multy_classification_model_v6(maxlen_actors, maxlen_plot, maxlen_features, maxlen_reviews, optimizer_version = None):\n",
    "    \n",
    "    sentenceLength_actors = maxlen_actors\n",
    "    vocab_size_frequent_words_actors = 20001\n",
    "    \n",
    "    sentenceLength_plot = maxlen_plot\n",
    "    vocab_size_frequent_words_plot = 17501\n",
    "    \n",
    "    sentenceLength_features = maxlen_features\n",
    "    vocab_size_frequent_words_features = 20001\n",
    "    \n",
    "    sentenceLength_reviews = maxlen_reviews\n",
    "    vocab_size_frequent_words_reviews = 40001\n",
    "    \n",
    "    model = keras.Sequential(name='MultyInput_Keras_Classification_model')\n",
    "    \n",
    "    actors = keras.Input(shape=(sentenceLength_actors,), name='actors_input')\n",
    "    plot = keras.Input(shape=(sentenceLength_plot,), name='plot_input')\n",
    "    features = keras.Input(shape=(sentenceLength_features,), name='features_input')\n",
    "    reviews = keras.Input(shape=(sentenceLength_reviews,), name='reviews_input')\n",
    "    \n",
    "    emb1 = layers.Embedding(input_dim = vocab_size_frequent_words_actors + 1,\n",
    "                            output_dim = neural_network_parameters['embedding_dimension'],\n",
    "                            embeddings_initializer = 'uniform',\n",
    "                            mask_zero = True,\n",
    "                            input_length = sentenceLength_actors,\n",
    "                            name=\"actors_embedding_layer\")(actors)\n",
    "    \n",
    "    encoded_layer1 = layers.GlobalMaxPooling1D(name=\"globalmaxpooling1\")(emb1)\n",
    "    \n",
    "    emb2 = layers.Embedding(input_dim = vocab_size_frequent_words_plot + 1,\n",
    "                            output_dim = neural_network_parameters['embedding_dimension'],\n",
    "                            embeddings_initializer = 'uniform',\n",
    "                            mask_zero = True,\n",
    "                            input_length = sentenceLength_plot,\n",
    "                            name=\"plot_embedding_layer\")(plot)\n",
    "    \n",
    "    encoded_layer2 = layers.GlobalMaxPooling1D(name=\"globalmaxpooling2\")(emb2)\n",
    "\n",
    "    emb3 = layers.Embedding(input_dim = vocab_size_frequent_words_features + 1,\n",
    "                            output_dim = neural_network_parameters['embedding_dimension'],\n",
    "                            embeddings_initializer = 'uniform',\n",
    "                            mask_zero = True,\n",
    "                            input_length = sentenceLength_features,\n",
    "                            name=\"features_embedding_layer\")(features)\n",
    "    \n",
    "    encoded_layer3 = layers.GlobalMaxPooling1D(name=\"globalmaxpooling3\")(emb3)\n",
    "    \n",
    "    emb4 = layers.Embedding(input_dim = vocab_size_frequent_words_reviews + 1,\n",
    "                            output_dim = neural_network_parameters['embedding_dimension'],\n",
    "                            embeddings_initializer = 'uniform',\n",
    "                            mask_zero = True,\n",
    "                            input_length = sentenceLength_reviews,\n",
    "                            name=\"reviews_embedding_layer\")(reviews)\n",
    "    \n",
    "    encoded_layer4 = layers.GlobalMaxPooling1D(name=\"globalmaxpooling4\")(emb4) #2D for images\n",
    "    \n",
    "    merged = layers.concatenate([encoded_layer1, encoded_layer2, encoded_layer3, encoded_layer4], axis=-1)\n",
    "\n",
    "    dense_layer_1 = layers.Dense(neural_network_parameters['batch_size'], \n",
    "                                 kernel_regularizer=regularizers.l2(neural_network_parameters['l2_regularization']),\n",
    "                                 activation=neural_network_parameters['dense_activation'],\n",
    "                                 name=\"1st_dense_layer\")(merged)\n",
    "    layers.Dropout(neural_network_parameters['dropout_rate'])(dense_layer_1)\n",
    "    \n",
    "    output_layer = layers.Dense(neural_network_parameters['number_target_variables'], activation=neural_network_parameters['output_activation'],\n",
    "                                name='output_layer')(dense_layer_1)\n",
    "    \n",
    "    model = keras.Model(inputs=[actors, plot, features, reviews], outputs=output_layer)\n",
    "    \n",
    "    print(model.output_shape)\n",
    "\n",
    "    print(model.summary())\n",
    "    \n",
    "    # Version_1 of Adam\n",
    "    if optimizer_version is None:\n",
    "        \n",
    "        optimizer = optimizer_adam_v2()\n",
    "    \n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=neural_network_parameters['model_loss'],\n",
    "                  metrics=[neural_network_parameters['model_metric']])\n",
    "    \n",
    "    plot_model(model, to_file='multy_input_keras_model.png')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BE CAREFUL...A TESTING APPROACH\n",
    "\n",
    "# Grid Search Parameters\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "neural_batch_size = [10, 20, 40, 60, 64, 80, 100, 128, 256, 512, 1024]\n",
    "embedding_dimension = [25, 50, 100]\n",
    "dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "l2_regularization = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform'] #embedding layer initializer\n",
    "\n",
    "batch_size_fit = [10, 20, 40, 60, 64, 80, 100, 128, 256, 512, 1024]\n",
    "lr_schedule_learning_rate = [0.001, 0.01, 0.1, 0.2, 0.3] # How to grid search this?\n",
    "lr_schedule_decay_rate = [1, 2, 3, 4] # How to grid search this?\n",
    " \n",
    "param_grid = dict(neural_batch_size=neural_batch_size, \n",
    "                  embedding_dimension=embedding_dimension, \n",
    "                  dropout_rate=dropout_rate,\n",
    "                  l2_regularization=l2_regularization, \n",
    "                  init_mode=init_mode, \n",
    "                  batch_size_fit=batch_size_fit,\n",
    "                  lr_schedule_learning_rate=lr_schedule_learning_rate, \n",
    "                  lr_schedule_decay_rate=lr_schedule_decay_rate)\n",
    "    \n",
    "def keras_multy_classification_model_gridsearchCV(maxlen_actors, maxlen_plot, maxlen_features, maxlen_reviews,\n",
    "                                                  neural_batch_size,\n",
    "                                                  embedding_dimension,\n",
    "                                                  dropout_rate,\n",
    "                                                  l2_regularization,\n",
    "                                                  init_mode,\n",
    "                                                  lr_schedule_learning_rate,\n",
    "                                                  lr_schedule_decay_rate,\n",
    "                                                  optimizer_version=None):\n",
    "    \n",
    "    sentenceLength_actors = maxlen_actors\n",
    "    vocab_size_frequent_words_actors = 20001\n",
    "    \n",
    "    sentenceLength_plot = maxlen_plot\n",
    "    vocab_size_frequent_words_plot = 17501\n",
    "    \n",
    "    sentenceLength_features = maxlen_features\n",
    "    vocab_size_frequent_words_features = 20001\n",
    "    \n",
    "    sentenceLength_reviews = maxlen_reviews\n",
    "    vocab_size_frequent_words_reviews = 40001\n",
    "    \n",
    "    model = keras.Sequential(name='MultyInput_Keras_Classification_model')\n",
    "    \n",
    "    actors = keras.Input(shape=(sentenceLength_actors,), name='actors_input')\n",
    "    plot = keras.Input(shape=(sentenceLength_plot,), name='plot_input')\n",
    "    features = keras.Input(shape=(sentenceLength_features,), name='features_input')\n",
    "    reviews = keras.Input(shape=(sentenceLength_reviews,), name='reviews_input')\n",
    "    \n",
    "    emb1 = layers.Embedding(input_dim = vocab_size_frequent_words_actors + 1,\n",
    "                            output_dim = embedding_dimension, #neural_network_parameters['embedding_dimension']\n",
    "                            embeddings_initializer = init_mode, #'uniform'\n",
    "                            mask_zero = True,\n",
    "                            input_length = sentenceLength_actors,\n",
    "                            name=\"actors_embedding_layer\")(actors)\n",
    "    \n",
    "    encoded_layer1 = layers.GlobalMaxPooling1D(name=\"globalmaxpooling1\")(emb1)\n",
    "    \n",
    "    emb2 = layers.Embedding(input_dim = vocab_size_frequent_words_plot + 1,\n",
    "                            output_dim = embedding_dimension, #neural_network_parameters['embedding_dimension']\n",
    "                            embeddings_initializer = init_mode, #'uniform'\n",
    "                            mask_zero = True,\n",
    "                            input_length = sentenceLength_plot,\n",
    "                            name=\"plot_embedding_layer\")(plot)\n",
    "    \n",
    "    encoded_layer2 = layers.GlobalMaxPooling1D(name=\"globalmaxpooling2\")(emb2)\n",
    "\n",
    "    emb3 = layers.Embedding(input_dim = vocab_size_frequent_words_features + 1,\n",
    "                            output_dim = embedding_dimension, #neural_network_parameters['embedding_dimension']\n",
    "                            embeddings_initializer = init_mode, #'uniform'\n",
    "                            mask_zero = True,\n",
    "                            input_length = sentenceLength_features,\n",
    "                            name=\"features_embedding_layer\")(features)\n",
    "    \n",
    "    encoded_layer3 = layers.GlobalMaxPooling1D(name=\"globalmaxpooling3\")(emb3)\n",
    "    \n",
    "    emb4 = layers.Embedding(input_dim = vocab_size_frequent_words_reviews + 1,\n",
    "                            output_dim = embedding_dimension, #neural_network_parameters['embedding_dimension']\n",
    "                            embeddings_initializer = init_mode, #'uniform'\n",
    "                            mask_zero = True,\n",
    "                            input_length = sentenceLength_reviews,\n",
    "                            name=\"reviews_embedding_layer\")(reviews)\n",
    "    \n",
    "    encoded_layer4 = layers.GlobalMaxPooling1D(name=\"globalmaxpooling4\")(emb4) #2D for images\n",
    "    \n",
    "    merged = layers.concatenate([encoded_layer1, encoded_layer2, encoded_layer3, encoded_layer4], axis=-1)\n",
    "\n",
    "    dense_layer_1 = layers.Dense(neural_batch_size, #neural_network_parameters['batch_size']\n",
    "                                 kernel_regularizer=regularizers.l2(l2_regularization), #neural_network_parameters['l2_regularization']\n",
    "                                 activation=neural_network_parameters['dense_activation'],\n",
    "                                 name=\"1st_dense_layer\")(merged)\n",
    "    layers.Dropout(dropout_rate)(dense_layer_1) #neural_network_parameters['dropout_rate']\n",
    "    \n",
    "    output_layer = layers.Dense(neural_network_parameters['number_target_variables'], activation=neural_network_parameters['output_activation'],\n",
    "                                name='output_layer')(dense_layer_1)\n",
    "    \n",
    "    model = keras.Model(inputs=[actors, plot, features, reviews], outputs=output_layer)\n",
    "    \n",
    "    print(model.output_shape)\n",
    "\n",
    "    print(model.summary())\n",
    "    \n",
    "    if optimizer_version is None:\n",
    "        \n",
    "        optimizer = optimizer_adam_v2()\n",
    "    \n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=neural_network_parameters['model_loss'],\n",
    "                  metrics=[neural_network_parameters['model_metric']])\n",
    "    \n",
    "    plot_model(model, to_file='multy_input_keras_model.png')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_seq_actors.shape)\n",
    "print(type(X_train_seq_actors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_seq_plot.shape)\n",
    "print(type(X_train_seq_plot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_seq_features.shape)\n",
    "print(type(X_train_seq_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_seq_reviews.shape)\n",
    "print(type(X_train_seq_reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.shape)\n",
    "print(type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test.shape)\n",
    "print(type(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prior to fitting the model: \n",
    "\n",
    "* X_train, X_test should have the form of an array with sequence of numbers.\n",
    "* y_train, y_test should have the form of a multi-hot encoded dataframe.\n",
    "\n",
    "<b> General observations: </b>\n",
    "\n",
    "* Reducing batch size can produce a better model (I should grid search on batch size).\n",
    "* Reducing the general number of parameters can produce better results.\n",
    "* Removing the second dense layer improved the results.\n",
    "* Removing regularization also affected the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 17)\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "actors_input (InputLayer)       [(None, 17)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "plot_input (InputLayer)         [(None, 23)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "features_input (InputLayer)     [(None, 60)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reviews_input (InputLayer)      [(None, 2067)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "actors_embedding_layer (Embeddi (None, 17, 50)       1000100     actors_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "plot_embedding_layer (Embedding (None, 23, 50)       875100      plot_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "features_embedding_layer (Embed (None, 60, 50)       1000100     features_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reviews_embedding_layer (Embedd (None, 2067, 50)     2000100     reviews_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "globalmaxpooling1 (GlobalMaxPoo (None, 50)           0           actors_embedding_layer[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "globalmaxpooling2 (GlobalMaxPoo (None, 50)           0           plot_embedding_layer[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "globalmaxpooling3 (GlobalMaxPoo (None, 50)           0           features_embedding_layer[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "globalmaxpooling4 (GlobalMaxPoo (None, 50)           0           reviews_embedding_layer[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 200)          0           globalmaxpooling1[0][0]          \n",
      "                                                                 globalmaxpooling2[0][0]          \n",
      "                                                                 globalmaxpooling3[0][0]          \n",
      "                                                                 globalmaxpooling4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "1st_dense_layer (Dense)         (None, 64)           12864       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 17)           1105        1st_dense_layer[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 4,889,369\n",
      "Trainable params: 4,889,369\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "\n",
      "Pre-trained weights not found. Fitting from start\n",
      "\n",
      "Epoch: 0, accuracy:0.9571,  loss:0.1659,  val_accuracy:0.9829,  val_loss:0.0740,  \n",
      "...........\n",
      "Training time finished. Duration 449.5009846687317 secs\n",
      "\n",
      "Table of training the keras text classification model\n",
      "\n",
      "+----+-----------+------------+------------+----------------+---------+\n",
      "|    |      loss |   accuracy |   val_loss |   val_accuracy |   epoch |\n",
      "|----+-----------+------------+------------+----------------+---------|\n",
      "|  1 | 0.16592   |   0.957066 |  0.0740364 |       0.982925 |       1 |\n",
      "|  2 | 0.0583985 |   0.987105 |  0.0463362 |       0.990343 |       2 |\n",
      "|  3 | 0.0443757 |   0.992225 |  0.0359179 |       0.993798 |       3 |\n",
      "|  4 | 0.0415623 |   0.99426  |  0.0342311 |       0.9946   |       4 |\n",
      "|  5 | 0.0360834 |   0.995199 |  0.0438007 |       0.994109 |       5 |\n",
      "|  6 | 0.036636  |   0.995316 |  0.0469117 |       0.993744 |       6 |\n",
      "|  7 | 0.0325893 |   0.996026 |  0.0382988 |       0.99451  |       7 |\n",
      "|  8 | 0.0317796 |   0.996359 |  0.0359937 |       0.99475  |       8 |\n",
      "|  9 | 0.030994  |   0.996616 |  0.0353879 |       0.994318 |       9 |\n",
      "| 10 | 0.0297834 |   0.9968   |  0.0358863 |       0.994618 |      10 |\n",
      "| 11 | 0.0280937 |   0.99704  |  0.0335776 |       0.995001 |      11 |\n",
      "+----+-----------+------------+------------+----------------+---------+\n",
      "\n",
      "Model's weights are saved\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9825/9825 - 1s - loss: 0.0740 - accuracy: 0.9829\n",
      "\n",
      "Test Score: 0.07403635839924558\n",
      "\n",
      "Test Accuracy: 0.98292464\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# RUN MLFLOW program\n",
    "\n",
    "model_repository = {}\n",
    "\n",
    "model_repository['Multiple Input Model'] = keras_multy_classification_model_v6(X_train_seq_actors.shape[1], \n",
    "                                                                               X_train_seq_plot.shape[1], \n",
    "                                                                               X_train_seq_features.shape[1], \n",
    "                                                                               X_train_seq_reviews.shape[1], \n",
    "                                                                               optimizer_version = None)\n",
    "with mlflow.start_run():\n",
    "    \n",
    "    model_directory = \"C:\\\\Users\\\\spano\\\\Desktop\\\\GitHub-Thesis\\\\models_text_classification\\\\model_one\"\n",
    "    \n",
    "    logdir = \".\\\\logs_test\\\\fit\\\\\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "    callbacks = callback(\"model_multy_input\", model_repository['Multiple Input Model'], logdir)\n",
    "\n",
    "    model_history = {}\n",
    "\n",
    "    model_history['experiment'] = fit_keras_multy_input(model_repository['Multiple Input Model'], \n",
    "                                                        X_train_seq_actors, #input_1\n",
    "                                                        X_train_seq_plot, #input_2\n",
    "                                                        X_train_seq_features, #input_3\n",
    "                                                        X_train_seq_reviews, #input4\n",
    "                                                        X_test_seq_actors, \n",
    "                                                        X_test_seq_plot, \n",
    "                                                        X_test_seq_features,\n",
    "                                                        X_test_seq_reviews,\n",
    "                                                        y_train, #output\n",
    "                                                        y_test, \n",
    "                                                        callbacks, #callback function\n",
    "                                                        fit_parameters[\"steps_per_epoch\"],\n",
    "                                                        fit_parameters[\"epoch\"],\n",
    "                                                        fit_parameters[\"verbose_fit\"],\n",
    "                                                        fit_parameters[\"batch_size_fit\"])\n",
    "\n",
    "    hist = pd.DataFrame(model_history['experiment'].history)\n",
    "    hist['epoch'] = model_history['experiment'].epoch\n",
    "    hist['epoch']+= 1\n",
    "    hist.index += 1\n",
    "    print(\"\\nTable of training the keras text classification model\\n\")\n",
    "    print(tabulate(hist, headers='keys', tablefmt='psql'))\n",
    "    \n",
    "    hist.to_pickle(\".\\\\model_one\\\\metrics_histogram_multi_input_keras.pkl\")\n",
    "    \n",
    "    save_model(model_repository['Multiple Input Model'], \"model_multy_input\")\n",
    "    \n",
    "    #version_1 of plot model\n",
    "    #plot_model_metrics(model_history['experiment'])\n",
    "    \n",
    "    #version_2 of plot model\n",
    "    plot_keras_history(model_history['experiment'])\n",
    "    \n",
    "    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "    model_evaluation = model_repository['Multiple Input Model'].evaluate([X_test_seq_actors, X_test_seq_plot, X_test_seq_features, X_test_seq_reviews], \n",
    "                                                                         y_test,\n",
    "                                                                         batch_size=fit_parameters[\"batch_size_fit\"],\n",
    "                                                                         verbose=2)\n",
    "    print('\\nTest Score:', model_evaluation[0])\n",
    "\n",
    "    print('\\nTest Accuracy:', model_evaluation[1])\n",
    "    \n",
    "    #neural_model params\n",
    "    mlflow.log_param(\"embedding_dimension\", neural_network_parameters['embedding_dimension'] )\n",
    "    mlflow.log_param(\"pool_size\", neural_network_parameters['pool_size'])\n",
    "    mlflow.log_param(\"padding\", neural_network_parameters['padding'])\n",
    "    mlflow.log_param(\"batch_size\", neural_network_parameters['batch_size'])\n",
    "    mlflow.log_param(\"l2_regularization\", neural_network_parameters['l2_regularization'])\n",
    "    mlflow.log_param(\"dropout_rate\", neural_network_parameters['dropout_rate'])\n",
    "    mlflow.log_param(\"dense_activation\", neural_network_parameters['dense_activation'])\n",
    "    mlflow.log_param(\"output_activation\",neural_network_parameters['output_activation'])\n",
    "    mlflow.log_param(\"model_loss\",neural_network_parameters['model_loss']) #takes any data type\n",
    "    mlflow.log_param(\"model_metric\",neural_network_parameters['model_metric'])\n",
    "    \n",
    "    #optimizer params\n",
    "    mlflow.log_param(\"lr_schedule_learning_rate\",optimizer_parameters['lr_schedule_learning_rate'])\n",
    "    mlflow.log_param(\"lr_schedule_decay_steps\",optimizer_parameters['lr_schedule_decay_steps'])\n",
    "    mlflow.log_param(\"lr_schedule_decay_rate\",optimizer_parameters['lr_schedule_decay_rate'])\n",
    "    mlflow.log_param(\"adam_amsgrad\",optimizer_parameters['staircase'])\n",
    "    \n",
    "    #fit_model params\n",
    "    mlflow.log_param(\"steps_per_epoch\",fit_parameters['steps_per_epoch'])\n",
    "    mlflow.log_param(\"fit_epoch\",fit_parameters['epoch'])\n",
    "    mlflow.log_param(\"verbose_fit\",fit_parameters['verbose_fit'])\n",
    "    mlflow.log_param(\"batch_size_fit\",fit_parameters['batch_size_fit']) #in generl batch_size_fit = neurons batch size\n",
    "    \n",
    "    #logging the model metrics\n",
    "    mlflow.log_metric(\"model_validation_loss\",model_evaluation[0]) #take only floats/integers\n",
    "    mlflow.log_metric(\"model_validation_accuracy\",model_evaluation[1])\n",
    "    \n",
    "    #mlflow.keras.save_model(model_repository['Multiple Input Model'], model_directory) -> deprecated\n",
    "    mlflow.keras.log_model(model_repository['Multiple Input Model'], \"keras-model-v6\")\n",
    "\n",
    "    #mlflow.tensorflow.log_model(tf_saved_model_dir = \"C:\\\\Users\\\\spano\\\\Desktop\\\\GitHub-Thesis\\\\models_text_classification\\\\model_one\\\\model_multy_input.h5\")\n",
    "#     mlflow.tensorflow.save_model(model_repository['Multiple Input Model'], model_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Model prediction </b>\n",
    "\n",
    "A good practice is to save the model predictions, to reproduce the classification report and compare it to other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.20055510e-05, 6.43491885e-03, 7.56604085e-03, 1.46603968e-04,\n",
       "       4.09325445e-03, 1.08695842e-01, 3.11477022e-04, 3.52195860e-03,\n",
       "       1.86906417e-03, 9.90697682e-01, 7.13763386e-03, 7.88883746e-01,\n",
       "       5.38973138e-04, 1.05217646e-03, 1.09881386e-01, 1.44818146e-03,\n",
       "       6.39846772e-02], dtype=float32)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use to yield probability distribution over the categories\n",
    "y_test_pred_probs = model_repository['Multiple Input Model'].predict([X_test_seq_actors, X_test_seq_plot, X_test_seq_features, X_test_seq_reviews])\n",
    "y_test_pred_probs[0]\n",
    "\n",
    "# y_predicted probabilities for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predictions = (y_test_pred_probs>0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_predictions[0]\n",
    "# y_predicted genre if equals to 1 (predicted genres of the movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]\n",
    "# the real genres of the movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\".//model_one//y_predictions_80-20_non-balanced_08022020\", y_test_predictions)\n",
    "np.save(\".//model_one//y_true_80-20_non-balanced_07022020\", y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\spano\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\spano\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      1363\n",
      "           1       0.51      0.23      0.31       774\n",
      "           2       0.68      0.20      0.30       415\n",
      "           3       0.97      0.58      0.72       438\n",
      "           4       1.00      1.00      1.00      2835\n",
      "           5       0.92      1.00      0.96       988\n",
      "           6       0.99      0.98      0.98       782\n",
      "           7       1.00      1.00      1.00      4553\n",
      "           8       0.25      0.02      0.04       398\n",
      "           9       0.98      0.99      0.99      1020\n",
      "          10       0.00      0.00      0.00       205\n",
      "          11       0.96      0.80      0.87       502\n",
      "          12       0.97      1.00      0.99      1201\n",
      "          13       0.99      0.97      0.98       552\n",
      "          14       0.99      1.00      1.00      1270\n",
      "          15       0.71      0.49      0.58       332\n",
      "          16       0.00      0.00      0.00       263\n",
      "\n",
      "   micro avg       0.97      0.87      0.92     17891\n",
      "   macro avg       0.76      0.66      0.69     17891\n",
      "weighted avg       0.91      0.87      0.88     17891\n",
      " samples avg       0.94      0.89      0.90     17891\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "classification_report= classification_report(y_true=y_test,\n",
    "                                             y_pred=y_test_predictions)\n",
    "print(classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Keras Model</th>\n",
       "      <th>Test Loss</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Multiple Inputs Model</td>\n",
       "      <td>0.074036</td>\n",
       "      <td>0.982925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Keras Model  Test Loss  Test Accuracy\n",
       "0  Multiple Inputs Model   0.074036       0.982925"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores = pd.DataFrame({'Keras Model':pd.Series(['Multiple Inputs Model'], dtype='str'),\n",
    "                         'Test Loss':pd.Series([model_evaluation[0]], dtype='float'),\n",
    "                         'Test Accuracy':pd.Series([model_evaluation[1]], dtype='float')})\n",
    "\n",
    "df_scores.to_pickle(\".\\\\model_one\\\\multy_input_keras_08022020.pkl\")\n",
    "\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicted vs Actual Genre Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_genre_tags(indx, model, genres_list):\n",
    "        \n",
    "    test_sequence_actors = X_test_seq_actors[indx:indx+1]\n",
    "    \n",
    "    test_sequence_plot = X_test_seq_plot[indx:indx+1]\n",
    "    \n",
    "    test_sequence_features = X_test_seq_features[indx:indx+1]\n",
    "    \n",
    "    test_sequence_reviews = X_test_seq_reviews[indx:indx+1]\n",
    "    \n",
    "    text_prediction = model.predict([test_sequence_actors, test_sequence_plot, test_sequence_features, test_sequence_reviews])\n",
    "    \n",
    "    [float(i) for i in text_prediction[0]]\n",
    "    \n",
    "    tag_probabilities = text_prediction[0][np.argsort(text_prediction[0])[-3:]]\n",
    "    \n",
    "    indexes = np.argsort(text_prediction[0])[::-1][:3]\n",
    "\n",
    "    predicted_tags = []\n",
    "    \n",
    "    for i, tag in enumerate(genres_list):\n",
    "        if i in indexes:\n",
    "            predicted_tags.append(genres_list[i])\n",
    "    \n",
    "    return predicted_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly saved numbers to make predictions: [4317, 8798, 7846, 3968, 2410]\n"
     ]
    }
   ],
   "source": [
    "random_numbers = random.sample(range(1, y_test.shape[0]), 5)\n",
    "\n",
    "save_index_of_numbers = random_numbers\n",
    "\n",
    "print(\"Randomly saved numbers to make predictions: {}\".format(save_index_of_numbers))\n",
    "\n",
    "with open('genres_list_08022020.pkl', 'rb') as handle:\n",
    "    genres_list = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=pd.read_pickle(\"C:\\\\Users\\\\spano\\\\Desktop\\\\GitHub-Thesis\\\\models_text_classification\\\\80-20 split_non-balanced\\\\x_test_08022020.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions = pd.DataFrame({'Movie Title':pd.Series([X_test['title'].iloc[save_index_of_numbers[0]]], dtype='str'),\n",
    "                               'Predicted Genre tags':pd.Series([predict_genre_tags(save_index_of_numbers[0], model_repository['Multiple Input Model'], genres_list)], dtype='str'),\n",
    "                               'Real Genre tags':pd.Series([X_test['reduced_genres'].iloc[save_index_of_numbers[0]]], dtype='str')})\n",
    "\n",
    "for i in range(len(save_index_of_numbers)):\n",
    "\n",
    "    df_predictions = df_predictions.append({'Movie Title':X_test['title'].iloc[save_index_of_numbers[i]], \n",
    "                                            'Predicted Genre tags':predict_genre_tags(save_index_of_numbers[i], model_repository['Multiple Input Model'], genres_list),\n",
    "                                            'Real Genre tags':X_test['reduced_genres'].iloc[save_index_of_numbers[i]]} , ignore_index=True)\n",
    "\n",
    "df_predictions = df_predictions.drop(df_predictions.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie Title</th>\n",
       "      <th>Predicted Genre tags</th>\n",
       "      <th>Real Genre tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Winning of Barbara Worth, The</td>\n",
       "      <td>[Drama, Musical, Romance]</td>\n",
       "      <td>[Drama, Romance, Western]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>The Last Witch Hunter</td>\n",
       "      <td>[Action, Adventure, Animation]</td>\n",
       "      <td>[Action, Adventure, Fantasy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Loving Story, The</td>\n",
       "      <td>[Documentary, Musical, War]</td>\n",
       "      <td>[Documentary]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Commune</td>\n",
       "      <td>[Documentary, Musical, War]</td>\n",
       "      <td>[Documentary]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Faster Pussycat! Kill! Kill!</td>\n",
       "      <td>[Action, Crime, Drama]</td>\n",
       "      <td>[Action, Crime, Drama]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Movie Title            Predicted Genre tags  \\\n",
       "1  Winning of Barbara Worth, The       [Drama, Musical, Romance]   \n",
       "2          The Last Witch Hunter  [Action, Adventure, Animation]   \n",
       "3              Loving Story, The     [Documentary, Musical, War]   \n",
       "4                        Commune     [Documentary, Musical, War]   \n",
       "5   Faster Pussycat! Kill! Kill!          [Action, Crime, Drama]   \n",
       "\n",
       "                Real Genre tags  \n",
       "1     [Drama, Romance, Western]  \n",
       "2  [Action, Adventure, Fantasy]  \n",
       "3                 [Documentary]  \n",
       "4                 [Documentary]  \n",
       "5        [Action, Crime, Drama]  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  </b>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
